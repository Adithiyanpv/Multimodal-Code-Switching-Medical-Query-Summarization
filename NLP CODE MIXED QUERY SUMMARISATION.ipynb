{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T14:53:20.774422Z",
     "iopub.status.busy": "2025-03-06T14:53:20.774116Z",
     "iopub.status.idle": "2025-03-06T14:53:20.807774Z",
     "shell.execute_reply": "2025-03-06T14:53:20.807071Z",
     "shell.execute_reply.started": "2025-03-06T14:53:20.774400Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    /kaggle/input/imagessss/Multimodal_images/skin...\n",
      "1    /kaggle/input/imagessss/Multimodal_images/skin...\n",
      "2    /kaggle/input/imagessss/Multimodal_images/skin...\n",
      "3    /kaggle/input/imagessss/Multimodal_images/swol...\n",
      "4    /kaggle/input/imagessss/Multimodal_images/skin...\n",
      "Name: Image_path, dtype: object\n",
      "✅ Image paths updated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ✅ Load CSV\n",
    "df = pd.read_csv(\"/kaggle/input/datasett/test (1).csv\")\n",
    "\n",
    "# ✅ Ensure correct replacement of \"/content\" with \"/kaggle/input/imagessss\"\n",
    "df[\"Image_path\"] = df[\"Image_path\"].str.replace(\"/content\", \"/kaggle/input/imagessss\", regex=False)\n",
    "\n",
    "# ✅ Also remove any unintended \"/kaggle/working/\" prefix\n",
    "df[\"Image_path\"] = df[\"Image_path\"].str.replace(\"/kaggle/working/\", \"/\", regex=False)\n",
    "\n",
    "# ✅ Save the updated CSV\n",
    "df.to_csv(\"valid_updated.csv\", index=False)\n",
    "\n",
    "# ✅ Check if the replacement worked\n",
    "print(df[\"Image_path\"].head())\n",
    "print(\"✅ Image paths updated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T14:53:23.743929Z",
     "iopub.status.busy": "2025-03-06T14:53:23.743597Z",
     "iopub.status.idle": "2025-03-06T14:53:23.771079Z",
     "shell.execute_reply": "2025-03-06T14:53:23.770386Z",
     "shell.execute_reply.started": "2025-03-06T14:53:23.743901Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    /kaggle/input/imagessss/Multimodal_images/skin...\n",
      "1    /kaggle/input/imagessss/Multimodal_images/skin...\n",
      "2    /kaggle/input/imagessss/Multimodal_images/swol...\n",
      "3    /kaggle/input/imagessss/Multimodal_images/skin...\n",
      "4    /kaggle/input/imagessss/Multimodal_images/skin...\n",
      "Name: Image_path, dtype: object\n",
      "✅ Image paths updated successfully!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ✅ Load CSV\n",
    "df = pd.read_csv(\"/kaggle/input/datasett/val (1).csv\")\n",
    "\n",
    "# ✅ Ensure correct replacement of \"/content\" with \"/kaggle/input/imagessss\"\n",
    "df[\"Image_path\"] = df[\"Image_path\"].str.replace(\"/content\", \"/kaggle/input/imagessss\", regex=False)\n",
    "\n",
    "# ✅ Also remove any unintended \"/kaggle/working/\" prefix\n",
    "df[\"Image_path\"] = df[\"Image_path\"].str.replace(\"/kaggle/working/\", \"/\", regex=False)\n",
    "\n",
    "# ✅ Save the updated CSV\n",
    "df.to_csv(\"test_updated.csv\", index=False)\n",
    "\n",
    "# ✅ Check if the replacement worked\n",
    "print(df[\"Image_path\"].head())\n",
    "print(\"✅ Image paths updated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T14:53:27.301419Z",
     "iopub.status.busy": "2025-03-06T14:53:27.301109Z",
     "iopub.status.idle": "2025-03-06T14:53:32.939480Z",
     "shell.execute_reply": "2025-03-06T14:53:32.938610Z",
     "shell.execute_reply.started": "2025-03-06T14:53:27.301396Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting evaluate\n",
      "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
      "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.28.1)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (19.0.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2025.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\n",
      "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: evaluate\n",
      "Successfully installed evaluate-0.4.3\n"
     ]
    }
   ],
   "source": [
    "!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T14:53:35.707985Z",
     "iopub.status.busy": "2025-03-06T14:53:35.707675Z",
     "iopub.status.idle": "2025-03-06T14:53:41.366116Z",
     "shell.execute_reply": "2025-03-06T14:53:41.365248Z",
     "shell.execute_reply.started": "2025-03-06T14:53:35.707958Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2.4.1)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rouge_score) (2024.2.0)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=7bea30252c2dfa5a82f95ad7523838ce70638ec9ad98f01f9b066876fae8bc3c\n",
      "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: rouge_score\n",
      "Successfully installed rouge_score-0.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T14:53:47.480834Z",
     "iopub.status.busy": "2025-03-06T14:53:47.480525Z",
     "iopub.status.idle": "2025-03-06T14:53:51.514739Z",
     "shell.execute_reply": "2025-03-06T14:53:51.513614Z",
     "shell.execute_reply.started": "2025-03-06T14:53:47.480807Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textstat\n",
      "  Downloading textstat-0.7.5-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pyphen (from textstat)\n",
      "  Downloading pyphen-0.17.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting cmudict (from textstat)\n",
      "  Downloading cmudict-1.0.32-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from textstat) (75.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict->textstat) (8.5.0)\n",
      "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.10/dist-packages (from cmudict->textstat) (5.13.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=5->cmudict->textstat) (3.21.0)\n",
      "Downloading textstat-0.7.5-py3-none-any.whl (105 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.3/105.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cmudict-1.0.32-py3-none-any.whl (939 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m939.4/939.4 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyphen-0.17.2-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pyphen, cmudict, textstat\n",
      "Successfully installed cmudict-1.0.32 pyphen-0.17.2 textstat-0.7.5\n"
     ]
    }
   ],
   "source": [
    "!pip install textstat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Section 0: Imports\n",
    "# --------------------------\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split  # (if needed for further splits)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from transformers import BartTokenizer, BartForConditionalGeneration, get_linear_schedule_with_warmup\n",
    "\n",
    "import evaluate\n",
    "from textstat import flesch_reading_ease  # For readability scores\n",
    "\n",
    "# --------------------------\n",
    "# Section 1: Data Preprocessing & Transforms\n",
    "# --------------------------\n",
    "def enhanced_clean_text(text):\n",
    "    \"\"\"\n",
    "    Clean codemixed text by lowercasing, fixing common quirks, and removing extra spaces.\n",
    "    \"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'sabse normal', 'most normal', text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Define image transformations for training and validation/test\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# --------------------------\n",
    "# Section 2: Dataset Definition\n",
    "# --------------------------\n",
    "class MultimodalDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, transform):\n",
    "        \"\"\"\n",
    "        data: pandas DataFrame with columns: 'Codemixed_Question', 'Image_path', 'summary'\n",
    "        tokenizer: BartTokenizer.\n",
    "        transform: Image transformation function.\n",
    "        \"\"\"\n",
    "        self.data = data.reset_index(drop=True)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        # Clean text and retrieve image path & summary\n",
    "        text = enhanced_clean_text(row['Codemixed_Question'])\n",
    "        image_path = row['Image_path']\n",
    "        summary = row['summary']\n",
    "\n",
    "        # Tokenize the input text\n",
    "        input_encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=512,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        input_ids = input_encoding.input_ids.squeeze(0)\n",
    "        attention_mask = input_encoding.attention_mask.squeeze(0)\n",
    "\n",
    "        # Tokenize the summary (target)\n",
    "        target_encoding = self.tokenizer(\n",
    "            summary,\n",
    "            max_length=150,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        labels = target_encoding.input_ids.squeeze(0)\n",
    "        labels[labels == self.tokenizer.pad_token_id] = -100  # ignore padding in loss\n",
    "\n",
    "        # Load and transform image\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,         \n",
    "            'attention_mask': attention_mask,  \n",
    "            'image': image,                 \n",
    "            'labels': labels                \n",
    "        }\n",
    "\n",
    "# --------------------------\n",
    "# Section 3: Data Loading\n",
    "# --------------------------\n",
    "# Assuming CSV files are stored in the working directory.\n",
    "train_csv_path = \"/kaggle/working/train_updated.csv\"\n",
    "valid_csv_path = \"/kaggle/working/valid_updated.csv\"\n",
    "test_csv_path  = \"/kaggle/working/test_updated.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_csv_path)\n",
    "valid_df = pd.read_csv(valid_csv_path)\n",
    "test_df  = pd.read_csv(test_csv_path)\n",
    "\n",
    "print(f\"Train set: {len(train_df)} samples\")\n",
    "print(f\"Validation set: {len(valid_df)} samples\")\n",
    "print(f\"Test set: {len(test_df)} samples\")\n",
    "\n",
    "# Initialize tokenizer (using DistilBART weights)\n",
    "tokenizer = BartTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
    "\n",
    "# Create dataset instances using respective transforms\n",
    "train_dataset = MultimodalDataset(train_df, tokenizer, train_transform)\n",
    "valid_dataset = MultimodalDataset(valid_df, tokenizer, val_transform)\n",
    "test_dataset  = MultimodalDataset(test_df, tokenizer, val_transform)\n",
    "\n",
    "# DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=2)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "test_dataloader  = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=2)\n",
    "\n",
    "# --------------------------\n",
    "# Section 4: Model Definition - MultimodalDistilBart\n",
    "# --------------------------\n",
    "class MultimodalDistilBart(nn.Module):\n",
    "    def __init__(self, tokenizer):\n",
    "        super(MultimodalDistilBart, self).__init__()\n",
    "        # Initialize Vision Transformer (ViT)\n",
    "        self.vit = models.vit_b_16(pretrained=True)\n",
    "        # Remove classification head to get raw features\n",
    "        self.vit.heads = nn.Identity()\n",
    "        # Freeze ViT parameters initially\n",
    "        for param in self.vit.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Load DistilBART weights for summarization\n",
    "        self.distilbart = BartForConditionalGeneration.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
    "        self.distilbart.resize_token_embeddings(len(tokenizer))\n",
    "        \n",
    "        # Projection layer: map ViT features (768) to DistilBART embedding space (1024)\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(768, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, image, labels=None):\n",
    "        # Get text embeddings from DistilBART's shared layer.\n",
    "        text_embeddings = self.distilbart.model.shared(input_ids)  # [B, seq_len, 1024]\n",
    "        \n",
    "        # Extract image features with ViT (use no_grad for frozen parameters)\n",
    "        with torch.no_grad():\n",
    "            image_features = self.vit(image)  # [B, 768]\n",
    "        projected_features = self.projection(image_features)  # [B, 1024]\n",
    "        projected_features = projected_features.unsqueeze(1)  # [B, 1, 1024]\n",
    "        \n",
    "        # Concatenate the image token with text embeddings\n",
    "        combined_embeddings = torch.cat([projected_features, text_embeddings], dim=1)  # [B, seq_len+1, 1024]\n",
    "        \n",
    "        # Adjust attention mask to account for extra image token\n",
    "        batch_size = attention_mask.size(0)\n",
    "        img_mask = torch.ones(batch_size, 1, dtype=attention_mask.dtype, device=attention_mask.device)\n",
    "        combined_attention_mask = torch.cat([img_mask, attention_mask], dim=1)\n",
    "        \n",
    "        # Forward pass through DistilBART\n",
    "        outputs = self.distilbart(\n",
    "            inputs_embeds=combined_embeddings,\n",
    "            attention_mask=combined_attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        return outputs\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = MultimodalDistilBart(tokenizer).to(device)\n",
    "\n",
    "# --------------------------\n",
    "# Section 5: Training Loop with Warmup & Differential Learning Rates\n",
    "# --------------------------\n",
    "optimizer = torch.optim.AdamW([\n",
    "    {'params': model.distilbart.parameters(), 'lr': 5e-5},\n",
    "    {'params': model.projection.parameters(), 'lr': 5e-5},\n",
    "    {'params': model.vit.parameters(), 'lr': 1e-5},\n",
    "])\n",
    "\n",
    "num_epochs = 10\n",
    "num_training_steps = len(train_dataloader) * num_epochs\n",
    "num_warmup_steps = int(0.1 * num_training_steps)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps,\n",
    "                                              num_training_steps=num_training_steps)\n",
    "\n",
    "scaler = GradScaler()\n",
    "accumulation_steps = 4  # Effective batch size = batch_size * accumulation_steps\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Initialize lists to record epoch losses\n",
    "train_loss_history = []\n",
    "valid_loss_history = []\n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 2\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # Unfreeze ViT parameters after 3 epochs for joint fine-tuning\n",
    "    if epoch == 3:\n",
    "        for param in model.vit.parameters():\n",
    "            param.requires_grad = True\n",
    "        print(f\"Epoch {epoch+1}: Unfreezing ViT parameters for fine-tuning.\")\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        image = batch['image'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(input_ids, attention_mask, image, labels)\n",
    "            loss = outputs.loss / accumulation_steps\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (step + 1) % accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item() * accumulation_steps\n",
    "        if (step + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}, Step {step+1}, Batch Loss: {loss.item() * accumulation_steps:.4f}\")\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    train_loss_history.append(avg_train_loss)\n",
    "    print(f\"Epoch {epoch+1} Training Loss: {avg_train_loss:.4f}\")\n",
    "    \n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in valid_dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            image = batch['image'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            outputs = model(input_ids, attention_mask, image, labels)\n",
    "            total_val_loss += outputs.loss.item()\n",
    "    \n",
    "    avg_val_loss = total_val_loss / len(valid_dataloader)\n",
    "    valid_loss_history.append(avg_val_loss)\n",
    "    print(f\"Epoch {epoch+1} Validation Loss: {avg_val_loss:.4f}\")\n",
    "    \n",
    "    \n",
    "torch.save(model.state_dict(), \"/kaggle/working/best_multimodal_distilbart.pth\")\n",
    "print(\"Model improved; checkpoint saved.\")\n",
    "    \n",
    "\n",
    "# --------------------------\n",
    "# Plot Training and Validation Loss\n",
    "# --------------------------\n",
    "epochs = range(1, len(train_loss_history) + 1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, train_loss_history, marker='o', label='Training Loss')\n",
    "plt.plot(epochs, valid_loss_history, marker='o', label='Validation Loss')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training vs. Validation Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"/kaggle/working/loss_plot.png\")\n",
    "plt.show()\n",
    "\n",
    "# --------------------------\n",
    "# Section 6: Inference Routine\n",
    "# --------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T15:24:04.379384Z",
     "iopub.status.busy": "2025-03-06T15:24:04.379055Z",
     "iopub.status.idle": "2025-03-06T15:26:26.685898Z",
     "shell.execute_reply": "2025-03-06T15:26:26.684986Z",
     "shell.execute_reply.started": "2025-03-06T15:24:04.379356Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bert_score\n",
      "  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.5.1+cu121)\n",
      "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.2.3)\n",
      "Requirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.47.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bert_score) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert_score) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.10/dist-packages (from bert_score) (4.67.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert_score) (3.7.5)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert_score) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->bert_score) (2025.1)\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.3.8)\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (1.2.4)\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (0.1.1)\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2025.0.1)\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2022.0.0)\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->bert_score) (2.4.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (4.12.2)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.28.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=3.0.0->bert_score) (0.4.5)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (1.4.7)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert_score) (3.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert_score) (2025.1.31)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->bert_score) (2022.0.0)\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->bert_score) (2024.2.0)\n",
      "Downloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bert_score\n",
      "Successfully installed bert_score-0.3.13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.7` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b790a2ca8d548d49b1bcd70554c8d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/5.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc14b0784c34ebeb13832de4d58da4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1100160564ca450c92e1f0f477fffccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading extra modules:   0%|          | 0.00/3.34k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da921fe0b3d54c23990244ffe5431098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c3d261aa2f4411a271af61d80c1cad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/482 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ced510e4c3a4972b1fe96a0e71276d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fc6e7fd168b49a5afea4945aa0f28a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8a544e86cb493ea717287adbf7e206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34075fe44fef4f14a47ca364729426bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.42G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Evaluation Results =====\n",
      "ROUGE: {'rouge1': 0.6009162280259486, 'rouge2': 0.3827452012001286, 'rougeL': 0.5169120825192468, 'rougeLsum': 0.5168313539047731}\n",
      "BLEU-1: 0.5753\n",
      "BLEU-2: 0.4665\n",
      "BLEU-3: 0.4038\n",
      "BLEU-4: 0.3620\n",
      "BERTScore (F1): 0.9192\n",
      "Average Readability (Prediction): 69.85\n",
      "Average Readability (Reference): 66.39\n",
      "Evaluation complete. Metrics saved to evaluation_metrics.json\n"
     ]
    }
   ],
   "source": [
    "!pip install bert_score\n",
    "def generate_summary(model, tokenizer, codemixed_question, image_path, device, transform):\n",
    "    \"\"\"\n",
    "    Generate a summary for a given codemixed question and image.\n",
    "    \"\"\"\n",
    "    cleaned_text = enhanced_clean_text(codemixed_question)\n",
    "    input_encoding = tokenizer(\n",
    "        cleaned_text,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    input_ids = input_encoding.input_ids.to(device)\n",
    "    attention_mask = input_encoding.attention_mask.to(device)\n",
    "    \n",
    "    # Process image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    text_embeddings = model.distilbart.model.shared(input_ids)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        image_features = model.vit(image)\n",
    "        projected_features = model.projection(image_features)\n",
    "    projected_features = projected_features.unsqueeze(1)\n",
    "    \n",
    "    combined_embeddings = torch.cat([projected_features, text_embeddings], dim=1)\n",
    "    batch_size = attention_mask.size(0)\n",
    "    img_mask = torch.ones(batch_size, 1, dtype=attention_mask.dtype, device=attention_mask.device)\n",
    "    combined_attention_mask = torch.cat([img_mask, attention_mask], dim=1)\n",
    "    \n",
    "    outputs = model.distilbart.generate(\n",
    "        inputs_embeds=combined_embeddings,\n",
    "        attention_mask=combined_attention_mask,\n",
    "        max_length=150,\n",
    "        num_beams=6,\n",
    "        temperature=0.7,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    generated_summary = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return generated_summary\n",
    "\n",
    "# --------------------------\n",
    "# Section 7: Advanced Evaluation Routine\n",
    "# --------------------------\n",
    "def compute_all_bleu(predictions, references):\n",
    "    \"\"\"\n",
    "    Compute BLEU-1 through BLEU-4 scores.\n",
    "    \"\"\"\n",
    "    bleu = evaluate.load('bleu')\n",
    "    bleu_scores = {}\n",
    "    for max_order in range(1, 5):\n",
    "        result = bleu.compute(predictions=predictions, references=[[ref] for ref in references], max_order=max_order)\n",
    "        bleu_scores[f\"BLEU-{max_order}\"] = result['bleu']\n",
    "    return bleu_scores\n",
    "\n",
    "def compute_readability(text):\n",
    "    \"\"\"\n",
    "    Compute Flesch Reading Ease score.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        score = flesch_reading_ease(text)\n",
    "    except Exception as e:\n",
    "        score = None\n",
    "    return score\n",
    "\n",
    "def evaluate_model(model, tokenizer, dataloader, device, transform):\n",
    "    model.eval()\n",
    "    rouge = evaluate.load('rouge')\n",
    "    bertscore = evaluate.load('bertscore')\n",
    "    \n",
    "    predictions = []\n",
    "    references = []\n",
    "    readability_pred = []\n",
    "    readability_ref = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            # Generate predictions batch-wise\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            images = batch['image'].to(device)\n",
    "            labels = batch['labels']\n",
    "            \n",
    "            # Decode reference summaries\n",
    "            for label in labels:\n",
    "                label_tokens = label[label != -100]  # Remove ignore tokens\n",
    "                ref_text = tokenizer.decode(label_tokens, skip_special_tokens=True)\n",
    "                references.append(ref_text)\n",
    "                readability_ref.append(compute_readability(ref_text))\n",
    "            \n",
    "            # Get text embeddings\n",
    "            text_embeddings = model.distilbart.model.shared(input_ids)\n",
    "            image_features = model.vit(images)\n",
    "            projected_features = model.projection(image_features).unsqueeze(1)\n",
    "            combined_embeddings = torch.cat([projected_features, text_embeddings], dim=1)\n",
    "            \n",
    "            batch_size = attention_mask.size(0)\n",
    "            img_mask = torch.ones(batch_size, 1, dtype=attention_mask.dtype, device=attention_mask.device)\n",
    "            combined_attention_mask = torch.cat([img_mask, attention_mask], dim=1)\n",
    "            \n",
    "            outputs = model.distilbart.generate(\n",
    "                inputs_embeds=combined_embeddings,\n",
    "                attention_mask=combined_attention_mask,\n",
    "                max_length=150,\n",
    "                num_beams=6,\n",
    "                temperature=0.7,\n",
    "                early_stopping=True\n",
    "            )\n",
    "            \n",
    "            for output in outputs:\n",
    "                pred_text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "                predictions.append(pred_text)\n",
    "                readability_pred.append(compute_readability(pred_text))\n",
    "    \n",
    "    # Compute metrics\n",
    "    rouge_scores = rouge.compute(predictions=predictions, references=references, use_stemmer=True)\n",
    "    bleu_scores = compute_all_bleu(predictions, references)\n",
    "    bertscore_result = bertscore.compute(predictions=predictions, references=references, lang=\"en\")\n",
    "    avg_bertscore_f1 = sum(bertscore_result['f1']) / len(bertscore_result['f1'])\n",
    "    \n",
    "    avg_readability_pred = sum(r for r in readability_pred if r is not None) / len(readability_pred)\n",
    "    avg_readability_ref  = sum(r for r in readability_ref if r is not None) / len(readability_ref)\n",
    "    \n",
    "    print(\"\\n===== Evaluation Results =====\")\n",
    "    print(\"ROUGE:\", rouge_scores)\n",
    "    for k, v in bleu_scores.items():\n",
    "        print(f\"{k}: {v:.4f}\")\n",
    "    print(f\"BERTScore (F1): {avg_bertscore_f1:.4f}\")\n",
    "    print(f\"Average Readability (Prediction): {avg_readability_pred:.2f}\")\n",
    "    print(f\"Average Readability (Reference): {avg_readability_ref:.2f}\")\n",
    "    \n",
    "    results = {\n",
    "        \"ROUGE\": rouge_scores,\n",
    "        **bleu_scores,\n",
    "        \"BERTScore_F1\": avg_bertscore_f1,\n",
    "        \"Avg_Readability_Pred\": avg_readability_pred,\n",
    "        \"Avg_Readability_Ref\": avg_readability_ref\n",
    "    }\n",
    "    return results\n",
    "\n",
    "# Example: Evaluate on Test Dataset\n",
    "eval_results = evaluate_model(model, tokenizer, test_dataloader, device, val_transform)\n",
    "\n",
    "# Optionally, save the evaluation results to a JSON file\n",
    "with open(\"/kaggle/working/evaluation_metrics.json\", \"w\") as f:\n",
    "    json.dump(eval_results, f, indent=4)\n",
    "\n",
    "print(\"Evaluation complete. Metrics saved to evaluation_metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-06T15:42:22.317192Z",
     "iopub.status.busy": "2025-03-06T15:42:22.316854Z",
     "iopub.status.idle": "2025-03-06T15:42:28.442279Z",
     "shell.execute_reply": "2025-03-06T15:42:28.441369Z",
     "shell.execute_reply.started": "2025-03-06T15:42:22.317163Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Generating summaries for the first few test samples:\n",
      "\n",
      "Sample 71\n",
      "--------------------------------------------------------------------------------\n",
      "Codemixed Question:\n",
      "Mere dental surgeon ne Thursday ko ek dental procedure conduct kiya tha. Humne socha ki wahan koi tumor hai, lekin wo use remove kar diya. Mere face par 9 stitches the. Procedure ke dauran mujhe IV antibiotics diye gaye aur ghar par Amoxicillin 500mg aur Hydrocodone 10/325 di gayi hai. Mai antibiotics ko bilkul sahi tarah le raha hoon. Dard bahut jyada ho raha hai, mai apne chehre ke us side ko bina yelping ke naahi chhu sakta. Kripya mere mouth mein kuch hua hai wo dekhiye. Surgical site yellowish dikh rahi hai lekin mujhe fever nahi hai. Dard ki dawa sirf kuch minutes ke liye hi relief de rahi hai. Kya ye infected ho raha hai?\n",
      "\n",
      "Reference Summary:\n",
      "Is the patient's excruciating pain and swelling, along with a yellowish surgical site, indicative of an infection? The image here shows the condition of mouth ulcers\n",
      "\n",
      "Generated Summary:\n",
      "Is the yellowish surgical site near the patient's mouth potentially infected after a dental procedure? The image shows the condition of mouth ulcers. White coloured circular patch/ swelling with red coloured margin present on the inner skin of lower lip, imner skin of left cheek, above the teeth and below the tongue.\n",
      "Condition- Aphthous ulcer\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Sample 72\n",
      "--------------------------------------------------------------------------------\n",
      "Codemixed Question:\n",
      "Mere dost ne sirf 5 din pehle hi c-section kiya hai..Uska section glue se bandh hua hai, lekin koi tape nahi hai uspar. Usne mujhe bola hai ki mujhe usko dekhna hai kyunki usse dard ho raha hai aur usko pata lagana hai ki kya wo infected hai. Mere paas bhi teen c-section huye hain. Jab maine dekha toh wo thoda sa khoon bhara hua aur thoda sujaa hua dikha aur aankh se peela dikha.Please doctor, mere aankh me kuch hua hai, kya ye normal hai. Main use turant apne doctor se sampark karne ko kaha.\n",
      "\n",
      "Reference Summary:\n",
      "Is it normal for a C-section incision to appear bloody, swollen, yellow, and cause pain? Should the doctor be contacted? The image shows the condition of eye inflamation. Entire lower section of eye is red swelled lines.\n",
      "\n",
      "Generated Summary:\n",
      "Is it normal to have a pimple-like bump under the eye after a C-section, with swelling and yellowish blood around it? The image shows the condition of swollen eye. Eye lid swollen with redness all over. Little swelling on the lower side of the eye as well.\n",
      "================================================================================\n",
      "\n",
      "Sample 73\n",
      "--------------------------------------------------------------------------------\n",
      "Codemixed Question:\n",
      "Mujhe Boulus (sp.) ke saath Erythema multiformae ka diagnosis hua hai, jisme meri skin par severe blistering rashes hai.Please doctor, dekhiye is vartaman condition ko.Mujhe Cyclosporine, Imuran(sp.) aur Prednisone prescribe kiya gaya hai (ek saath nahi) lekin koi aaram nahi mil raha hai. Mujhe isse past 15 saal se suffer kar rahi hai aur prednisone hi cheez thi jo \"stop\" kar sakti thi isko spread hone se, lekin ab wo bhi kar nahi paa rahi hai. Aur isko lene ke baad (jab ye bahut badh jaati hai) mujhe Michelin Man ki tarah dikhai deti hai aur maine suna hai ki ye liver ke liye bahut khatarnak hai...kisi herbal cheez ke liye koi suggestion hai jo scary side effects ke bina ho, uska sawaal bharpoor appreciate hoga.Thank You!!!!\n",
      "\n",
      "Reference Summary:\n",
      "Query: Patient diagnosed with Bullous Erythema Multiforme, severe blistering rashes, ineffective prescribed medications, seeking herbal alternatives without side effects. Suggestions? The image shows the condition of skin rash.  Pinkish red multuiple single coloured rash on the skin present close to each other.\n",
      "\n",
      "Generated Summary:\n",
      "What herbal suggestion can be suggested for a patient with erythema multiformae, severe blistering rashes, and liver issues? The image shows the condition of skin rash.  Pinkish red multuiple single coloured rash on the skin present close to each other.\n",
      "================================================================================\n",
      "\n",
      "Sample 74\n",
      "--------------------------------------------------------------------------------\n",
      "Codemixed Question:\n",
      " Namaste! Mera naam Nisar hai. Main 57 saal ka hoon. Mujhe hepatitus C hai 26 February 2009 se. Mujhe ye symptoms hai: Pait mein sujan ka hona (ascites), pairon mein sujan ke karan  Doctor, please look at the image of his below, ya poora badan sujna (anasarca), Baar-baar peela hona Thakan Neend mein disturb hona Khujli wali twacha Bhukh kam hona, wajan kam hona, dubla padna Khoon wali ulti Hosh mein na rehna, susti, bahut neend aana ya bhram (hepatic encephalopathy) Please mujhe madad karein.\n",
      "\n",
      "Reference Summary:\n",
      "What is the cause of the patient's persistent jaundice, fluid retention, fatigue, itching, weight loss, and mental disturbances? The image here shows a medical condition related to edema. Bothe legs are swollen with bruises. The legs have shown deformation\n",
      "\n",
      "Generated Summary:\n",
      "What could be the possible causes of a 57-year-old man with Hepatitis C, ascites, lip swelling, difficulty breathing, fatigue, and other symptoms? The image here shows a medical condition related to knee_swelling. the right leg is swollen and there are mild redness in the skin.\n",
      "================================================================================\n",
      "\n",
      "Sample 75\n",
      "--------------------------------------------------------------------------------\n",
      "Codemixed Question:\n",
      "Mere 3 saal ke lagbhag 4 saal ke bete ko kal subah uthne par rona aaya aur usne apne left leg mein dard ki shikayat ki. Tab se usne is par khade hone ya chalne se inkar kar diya hai. Koi saaf dikhne wala sujan, dhamni ya bruising nahi hai. Please doctor, dekhiye is vartaman condition ko. Wo bed par ya sofa par idhar udhar ghumta rehta hai par...bass use us par thoda pressure daalna hi kuchh nahi karata aur ise upar se bhi bend kar deta hai aur sahayta aur prashansa ke sath ise phir se hag kar deta hai. Aaj uska appointment hai ise dekhane ke liye par kuchh aur ray ki jankari lena chahte hain. Dhanyavaad.\n",
      "\n",
      "Reference Summary:\n",
      "Summary: 3-year-old boy woke up with left knee pain, refusing to stand or walk, no obvious swelling or deformity. Seeking additional opinions. The image here shows a medical condition related to knee_swelling. There is swelling in the knee.\n",
      "\n",
      "Generated Summary:\n",
      "What appointment is recommended for a 3-year-old with left leg pain, swelling, numbness, and a history of head trauma? The image here shows a medical condition related to knee_swelling. The knees in both of the legs have swollen and there is also slight deformation\n",
      "================================================================================\n",
      "\n",
      "Sample 76\n",
      "--------------------------------------------------------------------------------\n",
      "Codemixed Question:\n",
      " Meri hatheli par ek daana hai jo exczema ki tarah lag raha hai, mujhe iss daane ko ek mahine ya do mahine se hai. Kya ye HIV rash ho sakta hai? Maine bahut saare exczema creams aur hydrocortisone try kiye hain, aur ye sirf itching mein madad karti hai, poori tarah se chala jaane ki koshish nahi karti hai. Daana laal hai lekin jab mein lotion ya kuch bhi lagata hoon, wo meri skin tone ke karib brown ho jata hai. Agar mein lotion ya kuch bhi nahi lagata, to wo shower ke baad sukha ho jata hai aur bahut khujli hoti hai. Maine ise kuch baar khujla kar kharaab kar diya hai, jahan se mujhe lagta hai ki ye red bumps huye hain. Iske image neeche diya gaya hai.\n",
      "\n",
      "Reference Summary:\n",
      "Is the persistent red, itchy rash on the arm resembling eczema possibly related to HIV infection? The image shows the condition of skin rash. Round and swollen spots on the skin, red in color and multiple in the affected area.\n",
      "\n",
      "Generated Summary:\n",
      "Is the patient's persistent rash with red bumps, darkening of skin tone, and dry, itchy skin after using lotion indicative of HIV infection? The image shows the condition of skin rash. Round and swollen spots on the skin, red in color and multiple in the affected area.\n",
      "================================================================================\n",
      "\n",
      "Sample 77\n",
      "--------------------------------------------------------------------------------\n",
      "Codemixed Question:\n",
      "Hello maine ek rash develop kiya hai, pehle paar ke aas-pass, bumped out hokar crusty aur dry feel hota hai. Please doctor, dekhiye is vartaman condition ko. Ab mere haatho par bhi hai, thodi itching feel hoti hai jaise mere skin ke neeche bumps ya spots hain, mere doctor ne kaha ki ye sirf mere liver se related hai kyunki main ek alcoholic hoon jiske liver aur kidney problems hain, lekin maine TV par kuch similar dekha tha aur usmein scabies bola gaya tha.\n",
      "\n",
      "Reference Summary:\n",
      "Could the crusty, dry rash on the ankles that has spread to the hands and is itchy be scabies or related to liver and kidney problems? The image shows the condition of skin rash. Round and swollen spots on the skin, red in color and multiple in the affected area.\n",
      "\n",
      "Generated Summary:\n",
      "What could be the cause of a rash with bumps, bumps, crusty, dry skin, and itching on the arms, possibly related to liver and kidney problems? The image shows the condition of skin rash. Round and swollen spots on the skin, red in color and multiple in the affected area.\n",
      "================================================================================\n",
      "\n",
      "Sample 78\n",
      "--------------------------------------------------------------------------------\n",
      "Codemixed Question:\n",
      "Main Sandhya hoon, 22 saal ki hoon, aur female hoon. Bangalore, India se hoon. Main ek MBBS student hoon. Mujhe ek mahine se chest pain ho rahi hai. Retro-sternal hai, squeezing type ki, aur intermittent nature hai. Uska image neeche attached hai. Lying down aur deep breathing par aggravate hoti hai aur aspirin lene par relieve ho jaati hai. Mujhe teen hafte se pitting type ki pedal edema notice ho rahi hai, jo knee tak hai, aur ek hafte se generalized bhi hai.\n",
      "\n",
      "Reference Summary:\n",
      "What could be the possible cause of Sandhya's retro-sternal chest pain, pedal edema, and generalized edema? The image here shows a medical condition related to edema. Both the legs are swelled with no redness and the skin have become black\n",
      "\n",
      "Generated Summary:\n",
      "What could be the cause of recurring chest pain, edema in the knee, pitting type edema, and generalized edema? The image here shows a medical condition related to edema. Both the legs are swelled with no redness and the skin have become black\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "separator = \"=\" * 80\n",
    "\n",
    "print(separator)\n",
    "print(\"Generating summaries for the first few test samples:\\n\")\n",
    "\n",
    "for i in range(70,78):\n",
    "    row = test_df.iloc[i]\n",
    "    codemixed_question = row['Codemixed_Question']\n",
    "    image_path = row['Image_path']\n",
    "    reference_summary = row['summary']\n",
    "    \n",
    "    generated_summary = generate_summary(model, tokenizer, codemixed_question, image_path, device, val_transform)\n",
    "    \n",
    "    print(f\"Sample {i+1}\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Codemixed Question:\")\n",
    "    print(codemixed_question)\n",
    "    print(\"\\nReference Summary:\")\n",
    "    print(reference_summary)\n",
    "    print(\"\\nGenerated Summary:\")\n",
    "    print(generated_summary)\n",
    "    print(separator + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6708315,
     "sourceId": 10807169,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6708339,
     "sourceId": 10807198,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
